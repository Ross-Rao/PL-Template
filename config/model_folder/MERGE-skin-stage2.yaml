# MERGE model using skin dataset

callbacks:  # inline definition of callbacks, don't change the name
  # relevant input arguments in main.py
  ModelCheckpoint:
    filename: "model_{epoch:02d}_{val_loss:.4f}"
    monitor: "val_loss"  # log in module/example_module.py
    save_top_k: 5
    mode: "min"
    save_last: True
#  EarlyStopping:
#    monitor: 'val_loss'
#    patience: 8
#    mode: 'min'
#    check_on_train_epoch_end: False
  TQDMProgressBar:
    refresh_rate: 1
  LearningRateLogger:
trainer:  # inline definition of trainer, don't change the name
  max_epochs: 400
  accelerator: 'gpu'
  devices: 1
  check_val_every_n_epoch: 1
  log_every_n_steps: 2
# module settings: used in module/example_module.py
criterion:
  criterion: 'MSELoss'
  criterion_params:
optimizer:
  optimizer: 'Adam'
  optimizer_params:
    lr: 0.001
    weight_decay: 0.0
model:
  model: 'GATNet'
  model_params:
    in_features: 256
    out_features: 250
    num_heads: 8
    drop_edge: 0.2
    layer_dims: [448, 384, 256]
lr_scheduler:
  lr_scheduler: 'get_linear_schedule_with_warmup'
  lr_scheduler_params:
    num_warmup_steps: 10
    num_training_steps: '${model_folder.trainer.max_epochs}'
  lr_scheduler_other_params:
    interval: 'epoch'
    frequency: 40
    monitor: 'val_loss'
